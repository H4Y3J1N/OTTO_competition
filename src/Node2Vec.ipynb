{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import Node2Vec\n",
    "import gc\n",
    "import polars as pl\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../models')\n",
    "from utils import *\n",
    "from Node2Vec import *\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pl.read_parquet('../data/train.parquet',\n",
    "                           columns=['session','aid'],\n",
    "                           low_memory= True,\n",
    "                          )\n",
    "test_df = pl.read_parquet('../data/test.parquet',columns=['session','aid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wikid\\AppData\\Local\\Temp\\ipykernel_17820\\738683804.py:5: DeprecationWarning: `DataFrame.with_column` has been renamed; this redirect is temporary, please use `.with_columns` instead\n",
      "  df = df.with_column(pl.col(\"aid\").shift(periods=1).over(\"session\")\n"
     ]
    }
   ],
   "source": [
    "# # 이전 세션(session)의 aid 값을 포함하는 그래프 데이터 저장\n",
    "\n",
    "# train_df = lagged_df(train_df)\n",
    "# test_df = lagged_df(test_df)\n",
    "\n",
    "# df = pl.concat([\n",
    "#     train_df,\n",
    "#     test_df\n",
    "#     ], how=\"vertical\")\n",
    "\n",
    "# df = generate_Graph(df)\n",
    "# torch.save(edges_torch_T,\"../output/all_edges_train_and_test.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_tensor = torch.load(\"../output/all_edges_train_and_test.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 223644219])\n"
     ]
    }
   ],
   "source": [
    "# 그래프 데이터 생성\n",
    "data = Data(edge_index=edges_tensor)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del edges_tensor\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Node2Vec(data.edge_index, embedding_dim=32, \n",
    "                 walk_length=10,                        # lenght of rw\n",
    "                 context_size=5, walks_per_node=10,\n",
    "                 num_negative_samples=2, \n",
    "                 p=0.2, q=0.5,                          # bias parameters\n",
    "                 sparse=True).to(device)\n",
    "optimizer = torch.optim.SparseAdam(list(model.parameters()), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로더(loader)와 옵티마이저(optimizer) 설정\n",
    "\n",
    "loader = model.loader(batch_size=128, shuffle=True,\n",
    "                      num_workers=6)\n",
    "optimizer = torch.optim.SparseAdam(list(model.parameters()), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(0, 12):\n",
    "    loss = Node2Vec_train()\n",
    "    print(f'Epoch: {epoch:02d}, Loss: {loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from annoy import AnnoyIndex\n",
    "\n",
    "index = AnnoyIndex(32, 'angular')\n",
    "\n",
    "for idx,idx_embedding in enumerate(model.state_dict()['embedding.weight'].cpu()):\n",
    "    index.add_item(idx, idx_embedding)\n",
    "    \n",
    "index.build(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_node2vec = model.cpu().state_dict()['embedding.weight'].numpy()\n",
    "np.save(\"node2vec_embeddings\",embeddings_node2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model, loader, optimizer, embeddings_node2vec\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation / Inference\n",
    "def evaluate(path, mode=\"validation\", n_neighbors=12):\n",
    "\n",
    "    test = pl.read_parquet(path)\n",
    "\n",
    "    session_types = ['clicks', 'carts', 'orders']\n",
    "    test_session_AIDs = test.to_pandas().reset_index(drop=True).groupby('session')['aid'].apply(list)\n",
    "    test_session_types = test.to_pandas().reset_index(drop=True).groupby('session')['type'].apply(list)\n",
    "\n",
    "    del test\n",
    "    gc.collect()\n",
    "    labels = []\n",
    "\n",
    "    type_weight_multipliers = {0: 1, 1: 6, 2: 3}\n",
    "\n",
    "    for AIDs, types in zip(test_session_AIDs, test_session_types):\n",
    "        if len(AIDs) >= 20:\n",
    "                # 만약 20개 이상 aids가 있다면 (over equals 20) candidates를 구성할 필요가 없다. 기존 로직으로 충분.\n",
    "            weights=np.logspace(0.1,1,len(AIDs),base=2, endpoint=True)-1\n",
    "            aids_temp=defaultdict(lambda: 0)\n",
    "            for aid,w,t in zip(AIDs,weights,types): \n",
    "                aids_temp[aid]+= w * type_weight_multipliers[t]\n",
    "\n",
    "            sorted_aids=[k for k, v in sorted(aids_temp.items(), key=lambda item: -item[1])]\n",
    "            labels.append(sorted_aids[:20])\n",
    "        else:\n",
    "            # 만약 20 aids to output가 없다면 -- candidates generate를 위해 word2vec embeddings을 사용한다.\n",
    "            AIDs = list(dict.fromkeys(AIDs[::-1]))\n",
    "\n",
    "            # most recent aid 찾아내기\n",
    "            most_recent_aid = AIDs[0]\n",
    "\n",
    "            # neighbors 찾아내기\n",
    "            nns = [i for i in index.get_nns_by_item(most_recent_aid, n_neighbors+1)[1:]]\n",
    "\n",
    "\n",
    "            labels.append((AIDs+nns)[:n_neighbors])\n",
    "\n",
    "    labels_as_strings = [' '.join([str(l) for l in lls]) for lls in labels]\n",
    "\n",
    "    predictions = pd.DataFrame(data={'session_type': test_session_AIDs.index, 'labels': labels_as_strings})\n",
    "\n",
    "    prediction_dfs = []\n",
    "\n",
    "    for st in session_types:\n",
    "        modified_predictions = predictions.copy()\n",
    "        modified_predictions.session_type = modified_predictions.session_type.astype('str') + f'_{st}'\n",
    "        prediction_dfs.append(modified_predictions)\n",
    "\n",
    "    sub = pd.concat(prediction_dfs).reset_index(drop=True)\n",
    "    \n",
    "    del prediction_dfs, predictions,labels_as_strings, labels, test_session_types,test_session_AIDs\n",
    "    gc.collect()\n",
    "    if mode==\"test\":\n",
    "        sub.to_csv(\"submission.csv\",index=False)\n",
    "        return sub\n",
    "    else:\n",
    "\n",
    "        sub['labels_2'] = sub['labels'].apply(lambda x : [int(s) for s in x.split(' ')])\n",
    "        submission = pd.DataFrame()\n",
    "        submission['session'] = sub.session_type.apply(lambda x: int(x.split('_')[0]))\n",
    "        submission['type'] = sub.session_type.apply(lambda x: x.split('_')[1])\n",
    "        submission['labels'] = sub.labels_2.apply(lambda x : [item for item in x[:] ]) #.apply(lambda x: [int(i) for i in x.split(',')[:20]])\n",
    "        test_labels = pd.read_parquet('/kaggle/input/otto-train-and-test-data-for-local-validation/test_labels.parquet')\n",
    "        test_labels = test_labels.merge(submission, how='left', on=['session', 'type'])\n",
    "        del sub,submission\n",
    "        gc.collect()\n",
    "        gc.collect()\n",
    "        test_labels['hits'] = test_labels.apply(lambda df: len(set(df.ground_truth).intersection(set(df.labels))), axis=1)\n",
    "        test_labels['gt_count'] = test_labels.ground_truth.str.len().clip(0,20)\n",
    "        recall_per_type = test_labels.groupby(['type'])['hits'].sum() / test_labels.groupby(['type'])['gt_count'].sum() \n",
    "        score = (recall_per_type * pd.Series({'clicks': 0.1, 'carts': 0.30, 'orders': 0.60})).sum()\n",
    "\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/kaggle/input/otto-train-and-test-data-for-local-validation/test.parquet\"\n",
    "validation_score = evaluate(path,mode=\"validation\",n_neighbors=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/kaggle/input/otto-full-optimized-memory-footprint/test.parquet\"\n",
    "test_submission = evaluate(path,mode=\"test\",n_neighbors=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next step\n",
    "# BayesianOptimization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
