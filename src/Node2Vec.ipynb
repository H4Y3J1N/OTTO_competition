{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import Node2Vec\n",
    "torch_geometric.__version__\n",
    "import gc\n",
    "import polars as pl\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pl.read_parquet('../data/train.parquet',\n",
    "                           columns=['session','aid'],\n",
    "                           low_memory= True,\n",
    "                          )\n",
    "test_df = pl.read_parquet('../data/test.parquet',columns=['session','aid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이전 세션(session)의 aid 값을 포함하는 그래프 데이터 저장\n",
    "\n",
    "def lagged_df(df):\n",
    "    # 이전 세션(session)의 aid 값을 새로운 열(column)로 추가\n",
    "    df = df.with_column(pl.col(\"aid\").shift(periods=1).over(\"session\")\n",
    "                              #.cast(pl.Int32)\n",
    "                              #.fill_null(pl.col(\"aid\"))\n",
    "                              .alias(\"prev_aid\"))\n",
    "    return df\n",
    "train_df = lagged_df(train_df)\n",
    "test_df = lagged_df(test_df)\n",
    "\n",
    "df = pl.concat([\n",
    "    train_df,\n",
    "    test_df\n",
    "], how=\"vertical\")\n",
    "edges_torch_T = torch.tensor(np.transpose(df[['prev_aid','aid']].to_numpy()),dtype=torch.long)\n",
    "torch.save(edges_torch_T,\"all_edges_train_and_test.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_tensor = torch.load(\"../output/all_edges_train_and_test.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프 데이터 생성\n",
    "data = Data(edge_index=edges_tensor)\n",
    "# edges_tensor라는 텐서(tensor)를 이용하여 그래프 데이터를 생성\n",
    "print(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data 클래스는 그래프 데이터를 저장하는 데 사용되는 클래스.\n",
    "edge_index 속성은 각 엣지(edge)의 시작 노드와 끝 노드를 표시하는 텐서(tensor).\n",
    "edge_index 텐서를 이용하여 그래프의 연결 상태를 나타내는 그래프 데이터를 생성할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del edges_tensor\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding graph using Node2Vec\n",
    "\n",
    "model = Node2Vec(data.edge_index, embedding_dim=32, \n",
    "                 walk_length=10,                        # lenght of rw\n",
    "                 context_size=5, walks_per_node=10,\n",
    "                 num_negative_samples=2, \n",
    "                 p=0.2, q=0.5,                             # bias parameters\n",
    "                 sparse=True).to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data.edge_index: 그래프에서의 엣지 정보를 나타내는 텐서.    \n",
    "embedding_dim=32: 노드 임베딩 벡터의 차원 수를 정의.    \n",
    "walk_length=10: Random Walk의 길이를 정의.    \n",
    "context_size=5: Skip-Gram 모델에서 사용되는 문맥 크기를 정의.    \n",
    "walks_per_node=10: 노드마다 실행되는 Random Walk의 횟수를 정의.    \n",
    "num_negative_samples=2: Skip-Gram 모델에서 사용되는 음수 샘플링의 수를 정의.    \n",
    "p=0.2, q=0.5: Node2Vec에서 사용되는 Random Walk의 바이어스 파라미터. p는 이전 노드로 돌아가기 쉬운 경로를 선호하는 경향이 있으며, q는 더 멀리 이동하는 경로를 선호하는 경향이 있다.    \n",
    "sparse=True: 엣지 인덱스가 희소 텐서일 경우 성능을 향상시키기 위해 True로 설정.    \n",
    ".to(device): 모델을 CPU 또는 GPU와 같은 디바이스로 이동.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = model.loader(batch_size=128, shuffle=True,\n",
    "                      num_workers=2)\n",
    "optimizer = torch.optim.SparseAdam(list(model.parameters()), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " def train():\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for pos_rw, neg_rw in tqdm(loader):\n",
    "            optimizer.zero_grad()\n",
    "            loss = model.loss(pos_rw.to(device), neg_rw.to(device))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        return total_loss / len(loader)\n",
    "\n",
    "for epoch in range(0, 12):\n",
    "    loss = train()\n",
    "    print(f'Epoch: {epoch:02d}, Loss: {loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from annoy import AnnoyIndex\n",
    "\n",
    "index = AnnoyIndex(32, 'angular')\n",
    "\n",
    "for idx,idx_embedding in enumerate(model.state_dict()['embedding.weight'].cpu()):\n",
    "    index.add_item(idx, idx_embedding)\n",
    "    \n",
    "index.build(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_node2vec = model.cpu().state_dict()['embedding.weight'].numpy()\n",
    "\n",
    "np.save(\"node2vec_embeddings\",embeddings_node2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model, loader, optimizer, embeddings_node2vec\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation / Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(path,mode=\"validation\",n_neighbors=12):\n",
    "\n",
    "\n",
    "    test = pl.read_parquet(path)\n",
    "\n",
    "    session_types = ['clicks', 'carts', 'orders']\n",
    "    test_session_AIDs = test.to_pandas().reset_index(drop=True).groupby('session')['aid'].apply(list)\n",
    "    test_session_types = test.to_pandas().reset_index(drop=True).groupby('session')['type'].apply(list)\n",
    "\n",
    "    del test\n",
    "    gc.collect()\n",
    "    labels = []\n",
    "\n",
    "    type_weight_multipliers = {0: 1, 1: 6, 2: 3}\n",
    "\n",
    "    for AIDs, types in zip(test_session_AIDs, test_session_types):\n",
    "        if len(AIDs) >= 20:\n",
    "                # if we have enough aids (over equals 20) we don't need to look for candidates! we just use the old logic\n",
    "            weights=np.logspace(0.1,1,len(AIDs),base=2, endpoint=True)-1\n",
    "            aids_temp=defaultdict(lambda: 0)\n",
    "            for aid,w,t in zip(AIDs,weights,types): \n",
    "                aids_temp[aid]+= w * type_weight_multipliers[t]\n",
    "\n",
    "            sorted_aids=[k for k, v in sorted(aids_temp.items(), key=lambda item: -item[1])]\n",
    "            labels.append(sorted_aids[:20])\n",
    "        else:\n",
    "            # here we don't have 20 aids to output -- we will use word2vec embeddings to generate candidates!\n",
    "            AIDs = list(dict.fromkeys(AIDs[::-1]))\n",
    "\n",
    "            # let's grab the most recent aid\n",
    "            most_recent_aid = AIDs[0]\n",
    "\n",
    "            # and look for some neighbors!\n",
    "            nns = [i for i in index.get_nns_by_item(most_recent_aid, n_neighbors+1)[1:]]\n",
    "\n",
    "\n",
    "            labels.append((AIDs+nns)[:n_neighbors])\n",
    "\n",
    "    labels_as_strings = [' '.join([str(l) for l in lls]) for lls in labels]\n",
    "\n",
    "    predictions = pd.DataFrame(data={'session_type': test_session_AIDs.index, 'labels': labels_as_strings})\n",
    "\n",
    "    prediction_dfs = []\n",
    "\n",
    "    for st in session_types:\n",
    "        modified_predictions = predictions.copy()\n",
    "        modified_predictions.session_type = modified_predictions.session_type.astype('str') + f'_{st}'\n",
    "        prediction_dfs.append(modified_predictions)\n",
    "\n",
    "    sub = pd.concat(prediction_dfs).reset_index(drop=True)\n",
    "    \n",
    "    del prediction_dfs, predictions,labels_as_strings, labels, test_session_types,test_session_AIDs\n",
    "    gc.collect()\n",
    "    if mode==\"test\":\n",
    "        sub.to_csv(\"submission.csv\",index=False)\n",
    "        return sub\n",
    "    else:\n",
    "\n",
    "        sub['labels_2'] = sub['labels'].apply(lambda x : [int(s) for s in x.split(' ')])\n",
    "        submission = pd.DataFrame()\n",
    "        submission['session'] = sub.session_type.apply(lambda x: int(x.split('_')[0]))\n",
    "        submission['type'] = sub.session_type.apply(lambda x: x.split('_')[1])\n",
    "        submission['labels'] = sub.labels_2.apply(lambda x : [item for item in x[:] ]) #.apply(lambda x: [int(i) for i in x.split(',')[:20]])\n",
    "        test_labels = pd.read_parquet('/kaggle/input/otto-train-and-test-data-for-local-validation/test_labels.parquet')\n",
    "        test_labels = test_labels.merge(submission, how='left', on=['session', 'type'])\n",
    "        del sub,submission\n",
    "        gc.collect()\n",
    "        gc.collect()\n",
    "        test_labels['hits'] = test_labels.apply(lambda df: len(set(df.ground_truth).intersection(set(df.labels))), axis=1)\n",
    "        test_labels['gt_count'] = test_labels.ground_truth.str.len().clip(0,20)\n",
    "        recall_per_type = test_labels.groupby(['type'])['hits'].sum() / test_labels.groupby(['type'])['gt_count'].sum() \n",
    "        score = (recall_per_type * pd.Series({'clicks': 0.1, 'carts': 0.30, 'orders': 0.60})).sum()\n",
    "\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/kaggle/input/otto-train-and-test-data-for-local-validation/test.parquet\"\n",
    "validation_score = evaluate(path,mode=\"validation\",n_neighbors=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/kaggle/input/otto-full-optimized-memory-footprint/test.parquet\"\n",
    "test_submission = evaluate(path,mode=\"test\",n_neighbors=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
