{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wikid\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv, GAE\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import optuna\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Input Data\n",
    "### Node Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load node2vec embeddings and node features\n",
    "node2vec_embeddings = np.load(\"./output/node_embeddings.npy\")\n",
    "aid_features = pl.read_parquet(\"./data/aid_features.parquet\").to_numpy()\n",
    "# pathing up kernel dead problem\n",
    "# aid_features_agg = pl.read_parquet(\"./data/aid_features_agg.parquet\")\n",
    "# aid_features_all = aid_features.join(aid_features_agg, on=\"aid\", how=\"inner\").drop(\"aid\").to_numpy()\n",
    "\n",
    "# Scaling node2vec embeddings and node features separately\n",
    "scaler_node2vec = StandardScaler()\n",
    "scaled_node2vec_embeddings = scaler_node2vec.fit_transform(node2vec_embeddings)\n",
    "\n",
    "scaler_features = StandardScaler()\n",
    "scaled_aid_features_all = scaler_features.fit_transform(aid_features)\n",
    "\n",
    "# Concatenate node2vec embeddings and node features\n",
    "features_and_embeddings = np.concatenate((scaled_node2vec_embeddings, scaled_aid_features_all), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del node2vec_embeddings,aid_features#,aid_features_all, aid_features_agg\n",
    "gc.collect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_parquet('./data/train.parquet')\n",
    "edge_weights = data.groupby(['session', 'aid']).size().reset_index(name='weight')\n",
    "\n",
    "edge_list = edge_weights[['session', 'aid']].values.tolist()\n",
    "edge_weights_list = edge_weights['weight'].values.tolist()\n",
    "\n",
    "edge_index = torch.tensor(edge_list, dtype=torch.long).t().contiguous()\n",
    "edge_attr = torch.tensor(edge_weights_list, dtype=torch.float).view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_data = Data(x=torch.tensor(features_and_embeddings), edge_index=edge_index, edge_attr=edge_attr)\n",
    "graph_data.n_id = torch.arange(graph_data.num_nodes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neighbor Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gSAGE_loader = NeighborLoader(\n",
    "    graph_data,\n",
    "    num_neighbors=[10,10],\n",
    "    batch_size=512)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GraphSAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use attr GraphSAGE\n",
    "# emsemble GAE\n",
    "\n",
    "class WeightedSAGEConv(SAGEConv):\n",
    "    def __init__(self, in_channels, out_channels, **kwargs):\n",
    "        super(WeightedSAGEConv, self).__init__(in_channels, out_channels, **kwargs)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight=None):\n",
    "        x = (x[0], x[1])\n",
    "        return super(WeightedSAGEConv, self).forward(x, edge_index, edge_weight)\n",
    "\n",
    "    \n",
    "class GraphSAGE(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "\n",
    "        self.num_layers = num_layers\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "\n",
    "        # Input layer\n",
    "        self.convs.append(WeightedSAGEConv(in_channels, hidden_channels))\n",
    "\n",
    "        # Hidden layers\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.convs.append(WeightedSAGEConv(hidden_channels, hidden_channels))\n",
    "\n",
    "        # Output layer\n",
    "        self.convs.append(WeightedSAGEConv(hidden_channels, out_channels))\n",
    "\n",
    "    def forward(self, x, adjs):\n",
    "        for i, (edge_index, edge_attr, size) in enumerate(adjs):\n",
    "            x_target = x[:size[1]]  # Target node features\n",
    "            x = self.convs[i]((x, x_target), edge_index, edge_attr)\n",
    "\n",
    "            if i != self.num_layers - 1:\n",
    "                x = F.relu(x)\n",
    "                x = F.dropout(x, p=0.5, training=self.training)\n",
    "\n",
    "        return x.log_softmax(dim=-1)\n",
    "\n",
    "#         # 이 추론 코드는 깃에서 뜯어와 함친 것. 그러므로 3개 라벨 분류 추론에 적합하지 않은 형태.\n",
    "#         # 두개 비교해 더 낫게 수정할 필요가 있음. \n",
    "#         # chat에게 하나씩 보여준 다음 두개의 장점을 결합해서 디벨롭 \n",
    "#     def inference(self, x_all, subgraph_loader, device):\n",
    "#         pbar = tqdm(total=x_all.size(0) * self.num_layers)\n",
    "#         pbar.set_description('Evaluating')\n",
    "\n",
    "#         for i in range(self.num_layers):\n",
    "#             xs = []\n",
    "#             for batch_size, n_id, adj in subgraph_loader:\n",
    "#                 edge_index, edge_attr, size = adj.to(device)\n",
    "#                 x = x_all[n_id].to(device)\n",
    "#                 x_target = x[:size[1]]\n",
    "#                 x = self.convs[i]((x, x_target), edge_index, edge_attr)\n",
    "#                 if i != self.num_layers - 1:\n",
    "#                     x = F.relu(x)\n",
    "#                 xs.append(x.cpu())\n",
    "\n",
    "#                 pbar.update(batch_size)\n",
    "\n",
    "#             x_all = torch.cat(xs, dim=0)\n",
    "\n",
    "#         pbar.close()\n",
    "#         return x_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_channels = 16\n",
    "num_features = graph_data.x.shape[1]\n",
    "hidden_channels = 32\n",
    "num_layers = 2\n",
    "model = GAE(GraphSAGE(num_features, hidden_channels, out_channels, num_layers)).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005,weight_decay=1e-5)\n",
    "scheduler = StepLR(optimizer, step_size=2, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(loader):\n",
    "    total_loss = 0\n",
    "    for subgraph in tqdm(loader):\n",
    "        optimizer.zero_grad()\n",
    "        z = model.encode(subgraph.x.float().to(device),subgraph.edge_index.to(device))\n",
    "        loss = model.recon_loss(z, pos_edge_index=subgraph.edge_index.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader), model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(0,10):\n",
    "    \n",
    "    loss,model = train(gSAGE_loader)\n",
    "    print(f'Epoch: {epoch:02d}, Loss: {loss:.4f}')\n",
    "torch.save(model,\"graphSage_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kernel dead problem"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
