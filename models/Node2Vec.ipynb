{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sessions = pd.DataFrame()\n",
    "chunks = pd.read_json(data_path / 'train.jsonl', lines=True, chunksize=100_000)\n",
    "\n",
    "for e, chunk in enumerate(chunks):\n",
    "    event_dict = {\n",
    "        'session': [],\n",
    "        'aid': [],\n",
    "        'ts': [],\n",
    "        'type': [],\n",
    "    }\n",
    "    if e < 2:\n",
    "        for session, events in zip(chunk['session'].tolist(), chunk['events'].tolist()):\n",
    "            for event in events:\n",
    "                event_dict['session'].append(session)\n",
    "                event_dict['aid'].append(event['aid'])\n",
    "                event_dict['ts'].append(event['ts'])\n",
    "                event_dict['type'].append(event['type'])\n",
    "        chunk_session = pd.DataFrame(event_dict)\n",
    "        train_sessions = pd.concat([train_sessions, chunk_session])\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "train_sessions = train_sessions.reset_index(drop=True)\n",
    "\n",
    "\n",
    "train_sessions['ts'] = pd.to_datetime(train_sessions['ts'], unit='ms')\n",
    "\n",
    "train_sessions['date'] = train_sessions['ts'].dt.date\n",
    "\n",
    "df_aug = train_sessions[train_sessions['date'] == pd.to_datetime('2022-08-01')]\n",
    "\n",
    "df_orders = train_sessions[train_sessions['type'] == 'orders']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_freq = df_orders['aid'].value_counts()\n",
    "user_freq = df_orders['session'].value_counts()\n",
    "\n",
    "items = item_freq[item_freq >= 10].index\n",
    "users = user_freq[user_freq >= 10].index\n",
    "\n",
    "filtered_df = df_orders[df_orders['aid'].isin(items) & df_orders['session'].isin(users)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_by_session = filtered_df.groupby('session').filter(lambda group: (group['type'] == 'orders').sum() > 5)\n",
    "\n",
    "final_df = filtered_df.groupby('aid').filter(lambda group: len(group) > 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = final_df.groupby(['session', 'aid']).size().reset_index(name='frequency')\n",
    "\n",
    "final_df = final_df.merge(freq, on=['session', 'aid'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.distplot(final_df['frequency'], kde=True, bins=30)\n",
    "\n",
    "plt.title('Distribution of frequency')\n",
    "plt.xlabel('Frequency')\n",
    "plt.ylabel('Density')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    G.add_node(row['session'], type='user')\n",
    "    G.add_node(row['aid'], type='item')\n",
    "    \n",
    "    G.add_edge(row['session'], row['aid'], weight=row['stars'])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
